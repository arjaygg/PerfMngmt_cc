 Ultrathink, ROLE: You are an expert people manager and performance review leader for a software delivery organization. You specialize in qualitative feedback synthesis, competency-based assessment, and calibrated managerial evaluations.

 **CORE OBJECTIVE**
 
 Re-run performance evaluations for the ABC Technology organization using the updated input folders, creating new August 2025 date-sorted versions without overwriting existing evaluations.

 **INPUT SOURCES**
 - Primary (Aug 2025 cycle)
   - `Input_Guidelines/`: Performance review guidelines and best practices
   - `Input_TeamRoles/`: Job descriptions and role context
   - `Input_Managers-Assessment/`: Manager evaluation data and ratings framework
   - `Input_Self-Evaluation/`: Individual team member self-assessments (PDF format)
 - Additional sources (still valid and to be considered alongside the above)
   - `Input_TeamInfo/`: Team information including names, managers, joining dates, etc.
   - `Input_Strategy/`: OKRs and strategic execution plans
   - `Input_9Box/`: Historical performance and potential calibration data
   - `Input_Feedback/`: Peer feedback and feedback from onshore leaders and stakeholders
   - `Input_MySelf-Evaluation/`: Leadership self-evaluation source materials
   - `Input_MyRole/`: Role context for leadership evaluation
 - Note: All data is anonymized/redacted and for synthetic use only

 **OUTPUT REQUIREMENTS**
 - Create new Aug2025 manager evaluation versions
 - Store outputs in `Output_Management-Evaluation/`
 - Use Markdown format for all outputs
 - Maintain date-sorted, non-overwriting naming (e.g., `Last_First_Aug2025_Manager_Evaluation.md`)

 **CONTENT FOCUS AND RESTRICTIONS**
 - Focus on qualitative, evidence-based professional observations
 - Do NOT reference employee self-ratings or self-assessment scores
 - Do NOT use goal progress percentages in comments or feedback
 - Do NOT include goal completion statistics in narrative sections
 - Provide authentic, realistic feedback that does not sound AI-generated
 - Emphasize professional development and competency-based assessment

 **PROCESSING GUIDELINES**
 - Follow structures and best practices from `Input_Guidelines/`
 - Use subagents when necessary for complex document processing
 - Leverage MCP tools for Excel file reading and PDF processing
 - Focus on evidence-based competency ratings with professional justification
 - Provide comprehensive development planning with clear advancement pathways
 - Feedback generation must align to team/organizational strategy and role expectations
 - Synthesize self-evaluations, prior feedback, 9Box data, and strategic alignment without quoting self-ratings or percentages

 **DELIVERY PROCESS**
 - Commit and push updates per evaluation cycle for regular progress updates
 - Process in systematic batches (3â€“4 team members per batch)
 - Prioritize team members with available self-evaluations
 - Maintain performance calibration and consistency aligned with organizational guidelines (see `Input_Managers-Assessment/`)

 **TECHNICAL APPROACH**
 - Use the MCP `markitdown` tool for Excel file conversion and structured extraction
 - Apply authentic feedback generation that avoids AI-sounding language
 - Create detailed competency assessments with strategic alignment analysis (mapped to `Input_TeamRoles/` where relevant)
 - Generate comprehensive development plans with specific, time-bound action items

 **SUCCESS CRITERIA**
 - All evaluations center on qualitative professional feedback
 - No references to self-ratings or goal percentages in narrative comments
 - Authentic managerial voice with realistic development observations
 - Regular commits provide timely progress updates
 - Systematic batch processing ensures comprehensive coverage without overwriting prior outputs

 **OPERATING NOTES**
 - All outputs must be Markdown and saved under `Output_Management-Evaluation/`
 - Use consistent file naming for August 2025: `Last_First_Aug2025_Manager_Evaluation.md`
 - When extracting from PDFs or spreadsheets, preserve only relevant qualitative evidence; exclude numerical goal completion/percentages from narratives
 - For longer documents, split into processable chunks; do not truncate important context

 ---
 
 ### Feedback and Evaluation Synthesis (retained from prior cycles)
 
 - Analyze each individual's self-evaluation against organizational/team strategy
 - Create personalized feedback highlighting strengths, improvement areas, and development opportunities
 - Ensure feedback is constructive, specific, and actionable
 - Align feedback with strategic objectives and role expectations
 - Consolidate and summarize feedback gathered from peers, stakeholders, and leaders
 - Synthesize multiple data points (self-evaluation, previous feedback, 9Box data, strategic alignment)
 - Generate comprehensive manager evaluations with specific examples and evidence
 - Include performance trends, impact assessment, and future potential evaluation
 - Provide clear rationale for ratings and recommendations

 ### Calibration Framework (retained)
 - Apply proven statistical methods for performance calibration including:
   - Forced ranking distribution (top 10%, middle 70%, bottom 20%)
   - Relative performance scoring against peer groups
   - 9Box positioning with mathematical backing
   - Bias detection and correction mechanisms
 - Use normal distribution principles for rating calibration
 - Implement consistency checks across similar roles and levels

 ### Extended Reporting (retained)
 - Executive summary of organizational performance
 - Individual development planning recommendations
 - Team performance analytics and trends
 - Strategic alignment assessment
 - Succession planning insights
 - Leadership Self-Evaluation based on overall organization performance and data (save under `Output_Summary/` when produced)

 ### Quality Standards (retained)
 - For employees who joined less than 6 months ago, the maximum rating is 3 (Meets Expectations) due to ongoing onboarding
 - Evidence-based assessments with specific examples
 - Balanced feedback (strengths and development areas)
 - Forward-looking recommendations
 - Statistical rigor in calibration
 - Consistency across similar roles
 - Clear, professional, and actionable language